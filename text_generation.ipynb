{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But as the riper should by time decease,\n",
      "  His tender heir might bear his memory:\n",
      "  But thou contracted to thine own bright eyes,\n",
      "  Feed'st thy light's flame with self-substantial fuel,\n",
      "  Making a famine where abundance lies,\n",
      "  Thy self thy foe, to thy sweet self too cruel:\n",
      "  Thou that art now the world's fresh ornament,\n",
      "  And only herald to the gaudy spring,\n",
      "  Within thine own bu\n"
     ]
    }
   ],
   "source": [
    "path_to_file = \"./Data/shakespeare.txt\"\n",
    "text = open(path_to_file, \"r\").read()\n",
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 ['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '>', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|', '}']\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(text))\n",
    "print(len(vocab),vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding: Letters to Numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are 84 unique characters in the shakespear corpus. We will use one-hot encoding to represent each character as a vector of length 84. The vector will have all zeros except for the index corresponding to the character, which will be 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '\\n')\n",
      "(1, ' ')\n",
      "(2, '!')\n",
      "(3, '\"')\n",
      "(4, '&')\n",
      "(5, \"'\")\n",
      "(6, '(')\n",
      "(7, ')')\n",
      "(8, ',')\n",
      "(9, '-')\n",
      "(10, '.')\n",
      "(11, '0')\n",
      "(12, '1')\n",
      "(13, '2')\n",
      "(14, '3')\n",
      "(15, '4')\n",
      "(16, '5')\n",
      "(17, '6')\n",
      "(18, '7')\n",
      "(19, '8')\n",
      "(20, '9')\n",
      "(21, ':')\n",
      "(22, ';')\n",
      "(23, '<')\n",
      "(24, '>')\n",
      "(25, '?')\n",
      "(26, 'A')\n",
      "(27, 'B')\n",
      "(28, 'C')\n",
      "(29, 'D')\n",
      "(30, 'E')\n",
      "(31, 'F')\n",
      "(32, 'G')\n",
      "(33, 'H')\n",
      "(34, 'I')\n",
      "(35, 'J')\n",
      "(36, 'K')\n",
      "(37, 'L')\n",
      "(38, 'M')\n",
      "(39, 'N')\n",
      "(40, 'O')\n",
      "(41, 'P')\n",
      "(42, 'Q')\n",
      "(43, 'R')\n",
      "(44, 'S')\n",
      "(45, 'T')\n",
      "(46, 'U')\n",
      "(47, 'V')\n",
      "(48, 'W')\n",
      "(49, 'X')\n",
      "(50, 'Y')\n",
      "(51, 'Z')\n",
      "(52, '[')\n",
      "(53, ']')\n",
      "(54, '_')\n",
      "(55, '`')\n",
      "(56, 'a')\n",
      "(57, 'b')\n",
      "(58, 'c')\n",
      "(59, 'd')\n",
      "(60, 'e')\n",
      "(61, 'f')\n",
      "(62, 'g')\n",
      "(63, 'h')\n",
      "(64, 'i')\n",
      "(65, 'j')\n",
      "(66, 'k')\n",
      "(67, 'l')\n",
      "(68, 'm')\n",
      "(69, 'n')\n",
      "(70, 'o')\n",
      "(71, 'p')\n",
      "(72, 'q')\n",
      "(73, 'r')\n",
      "(74, 's')\n",
      "(75, 't')\n",
      "(76, 'u')\n",
      "(77, 'v')\n",
      "(78, 'w')\n",
      "(79, 'x')\n",
      "(80, 'y')\n",
      "(81, 'z')\n",
      "(82, '|')\n",
      "(83, '}')\n"
     ]
    }
   ],
   "source": [
    "for pair in enumerate(vocab):\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '!': 2,\n",
       " '\"': 3,\n",
       " '&': 4,\n",
       " \"'\": 5,\n",
       " '(': 6,\n",
       " ')': 7,\n",
       " ',': 8,\n",
       " '-': 9,\n",
       " '.': 10,\n",
       " '0': 11,\n",
       " '1': 12,\n",
       " '2': 13,\n",
       " '3': 14,\n",
       " '4': 15,\n",
       " '5': 16,\n",
       " '6': 17,\n",
       " '7': 18,\n",
       " '8': 19,\n",
       " '9': 20,\n",
       " ':': 21,\n",
       " ';': 22,\n",
       " '<': 23,\n",
       " '>': 24,\n",
       " '?': 25,\n",
       " 'A': 26,\n",
       " 'B': 27,\n",
       " 'C': 28,\n",
       " 'D': 29,\n",
       " 'E': 30,\n",
       " 'F': 31,\n",
       " 'G': 32,\n",
       " 'H': 33,\n",
       " 'I': 34,\n",
       " 'J': 35,\n",
       " 'K': 36,\n",
       " 'L': 37,\n",
       " 'M': 38,\n",
       " 'N': 39,\n",
       " 'O': 40,\n",
       " 'P': 41,\n",
       " 'Q': 42,\n",
       " 'R': 43,\n",
       " 'S': 44,\n",
       " 'T': 45,\n",
       " 'U': 46,\n",
       " 'V': 47,\n",
       " 'W': 48,\n",
       " 'X': 49,\n",
       " 'Y': 50,\n",
       " 'Z': 51,\n",
       " '[': 52,\n",
       " ']': 53,\n",
       " '_': 54,\n",
       " '`': 55,\n",
       " 'a': 56,\n",
       " 'b': 57,\n",
       " 'c': 58,\n",
       " 'd': 59,\n",
       " 'e': 60,\n",
       " 'f': 61,\n",
       " 'g': 62,\n",
       " 'h': 63,\n",
       " 'i': 64,\n",
       " 'j': 65,\n",
       " 'k': 66,\n",
       " 'l': 67,\n",
       " 'm': 68,\n",
       " 'n': 69,\n",
       " 'o': 70,\n",
       " 'p': 71,\n",
       " 'q': 72,\n",
       " 'r': 73,\n",
       " 's': 74,\n",
       " 't': 75,\n",
       " 'u': 76,\n",
       " 'v': 77,\n",
       " 'w': 78,\n",
       " 'x': 79,\n",
       " 'y': 80,\n",
       " 'z': 81,\n",
       " '|': 82,\n",
       " '}': 83}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_ind = {char:ind for ind,char in enumerate(vocab)}\n",
    "char_to_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_ind[\"H\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_to_char = np.array(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'H'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_to_char[33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  1, ..., 30, 39, 29])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text = np.array([char_to_ind[c] for c in text])\n",
    "encoded_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so there are around 5.5 Million words inside the shakespeare.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5445609"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But as the riper should by time decease,\n",
      "  His tender heir might bear his memory:\n",
      "  But thou contracted to thine own bright eyes,\n",
      "  Feed'st thy light's flame with self-substantial fuel,\n",
      "  Making a famine where abundance lies,\n",
      "  Thy self thy foe, to thy sweet self too cruel:\n",
      "  Thou that art now the world's fresh ornament,\n",
      "  And only herald to the gaudy spring,\n",
      "  Within thine own bu\n"
     ]
    }
   ],
   "source": [
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1, 12,  0,  1,  1, 31, 73, 70, 68,  1, 61, 56, 64,\n",
       "       73, 60, 74, 75,  1, 58, 73, 60, 56, 75, 76, 73, 60, 74,  1, 78, 60,\n",
       "        1, 59, 60, 74, 64, 73, 60,  1, 64, 69, 58, 73, 60, 56, 74, 60,  8,\n",
       "        0,  1,  1, 45, 63, 56, 75,  1, 75, 63, 60, 73, 60, 57, 80,  1, 57,\n",
       "       60, 56, 76, 75, 80,  5, 74,  1, 73, 70, 74, 60,  1, 68, 64, 62, 63,\n",
       "       75,  1, 69, 60, 77, 60, 73,  1, 59, 64, 60,  8,  0,  1,  1, 27, 76,\n",
       "       75,  1, 56, 74,  1, 75, 63, 60,  1, 73, 64, 71, 60, 73,  1, 74, 63,\n",
       "       70, 76, 67, 59,  1, 57, 80,  1, 75, 64, 68, 60,  1, 59, 60, 58, 60,\n",
       "       56, 74, 60,  8,  0,  1,  1, 33, 64, 74,  1, 75, 60, 69, 59, 60, 73,\n",
       "        1, 63, 60, 64, 73,  1, 68, 64, 62, 63, 75,  1, 57, 60, 56, 73,  1,\n",
       "       63, 64, 74,  1, 68, 60, 68, 70, 73, 80, 21,  0,  1,  1, 27, 76, 75,\n",
       "        1, 75, 63, 70, 76,  1, 58, 70, 69, 75, 73, 56, 58, 75, 60, 59,  1,\n",
       "       75, 70,  1, 75, 63, 64, 69, 60,  1, 70, 78, 69,  1, 57, 73, 64, 62,\n",
       "       63, 75,  1, 60, 80, 60, 74,  8,  0,  1,  1, 31, 60, 60, 59,  5, 74,\n",
       "       75,  1, 75, 63, 80,  1, 67, 64, 62, 63, 75,  5, 74,  1, 61, 67, 56,\n",
       "       68, 60,  1, 78, 64, 75, 63,  1, 74, 60, 67, 61,  9, 74, 76, 57, 74,\n",
       "       75, 56, 69, 75, 64, 56, 67,  1, 61, 76, 60, 67,  8,  0,  1,  1, 38,\n",
       "       56, 66, 64, 69, 62,  1, 56,  1, 61, 56, 68, 64, 69, 60,  1, 78, 63,\n",
       "       60, 73, 60,  1, 56, 57, 76, 69, 59, 56, 69, 58, 60,  1, 67, 64, 60,\n",
       "       74,  8,  0,  1,  1, 45, 63, 80,  1, 74, 60, 67, 61,  1, 75, 63, 80,\n",
       "        1, 61, 70, 60,  8,  1, 75, 70,  1, 75, 63, 80,  1, 74, 78, 60, 60,\n",
       "       75,  1, 74, 60, 67, 61,  1, 75, 70, 70,  1, 58, 73, 76, 60, 67, 21,\n",
       "        0,  1,  1, 45, 63, 70, 76,  1, 75, 63, 56, 75,  1, 56, 73, 75,  1,\n",
       "       69, 70, 78,  1, 75, 63, 60,  1, 78, 70, 73, 67, 59,  5, 74,  1, 61,\n",
       "       73, 60, 74, 63,  1, 70, 73, 69, 56, 68, 60, 69, 75,  8,  0,  1,  1,\n",
       "       26, 69, 59,  1, 70, 69, 67, 80,  1, 63, 60, 73, 56, 67, 59,  1, 75,\n",
       "       70,  1, 75, 63, 60,  1, 62, 56, 76, 59, 80,  1, 74, 71, 73, 64, 69,\n",
       "       62,  8,  0,  1,  1, 48, 64, 75, 63, 64, 69,  1, 75, 63, 64, 69, 60,\n",
       "        1, 70, 78, 69,  1, 57, 76])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But as the riper should by time decease,\n",
      "  His tender heir might bear his memory:\n",
      "  But thou contracted to thine own bright eyes,\n",
      "  Feed'st thy light's flame with self-substantial fuel,\n",
      "  Making a famine where abundance lies,\n",
      "  Thy self thy foe, to thy sweet self too cruel:\n",
      "  Thou that art now the world's fresh ornament,\n",
      "  And only herald to the gaudy spring,\n",
      "  Within thine own bu\n"
     ]
    }
   ],
   "source": [
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"From fairest creatures we desire increase,\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"\"\"From fairest creatures we desire increase,\n",
    "  That thereby beauty's rose might never die,\n",
    "  But as the riper should by time decease,\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a rhyme in almost every 3rd line, so in order for our model to find patterns, it must read atleast 3 lines: around 130 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41569"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_seq = len(text) // (seq_length + 1)\n",
    "total_seq  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting to Tensors: Creating Batches\n",
    "SO we can easily feed them to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.TensorSliceDataset"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)\n",
    "type(char_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "12\n",
      "0\n",
      "1\n",
      "1\n",
      "31\n",
      "73\n",
      "70\n",
      "68\n",
      "1\n",
      "61\n",
      "56\n",
      "64\n",
      "73\n",
      "60\n",
      "74\n",
      "75\n",
      "1\n",
      "58\n",
      "73\n",
      "60\n",
      "56\n",
      "75\n",
      "76\n",
      "73\n",
      "60\n",
      "74\n",
      "1\n",
      "78\n",
      "60\n",
      "1\n",
      "59\n",
      "60\n",
      "74\n",
      "64\n",
      "73\n",
      "60\n",
      "1\n",
      "64\n",
      "69\n",
      "58\n",
      "73\n",
      "60\n",
      "56\n",
      "74\n",
      "60\n",
      "8\n",
      "0\n",
      "1\n",
      "1\n",
      "45\n",
      "63\n",
      "56\n",
      "75\n",
      "1\n",
      "75\n",
      "63\n",
      "60\n",
      "73\n",
      "60\n",
      "57\n",
      "80\n",
      "1\n",
      "57\n",
      "60\n",
      "56\n",
      "76\n",
      "75\n",
      "80\n",
      "5\n",
      "74\n",
      "1\n",
      "73\n",
      "70\n",
      "74\n",
      "60\n",
      "1\n",
      "68\n",
      "64\n",
      "62\n",
      "63\n",
      "75\n",
      "1\n",
      "69\n",
      "60\n",
      "77\n",
      "60\n",
      "73\n",
      "1\n",
      "59\n",
      "64\n",
      "60\n",
      "8\n",
      "0\n",
      "1\n",
      "1\n",
      "27\n",
      "76\n",
      "75\n",
      "1\n",
      "56\n",
      "74\n",
      "1\n",
      "75\n",
      "63\n",
      "60\n",
      "1\n",
      "73\n",
      "64\n",
      "71\n",
      "60\n",
      "73\n",
      "1\n",
      "74\n",
      "63\n",
      "70\n",
      "76\n",
      "67\n",
      "59\n",
      "1\n",
      "57\n",
      "80\n",
      "1\n",
      "75\n",
      "64\n",
      "68\n",
      "60\n",
      "1\n",
      "59\n",
      "60\n",
      "58\n",
      "60\n",
      "56\n",
      "74\n",
      "60\n",
      "8\n",
      "0\n",
      "1\n",
      "1\n",
      "33\n",
      "64\n",
      "74\n",
      "1\n",
      "75\n",
      "60\n",
      "69\n",
      "59\n",
      "60\n",
      "73\n",
      "1\n",
      "63\n",
      "60\n",
      "64\n",
      "73\n",
      "1\n",
      "68\n",
      "64\n",
      "62\n",
      "63\n",
      "75\n",
      "1\n",
      "57\n",
      "60\n",
      "56\n",
      "73\n",
      "1\n",
      "63\n",
      "64\n",
      "74\n",
      "1\n",
      "68\n",
      "60\n",
      "68\n",
      "70\n",
      "73\n",
      "80\n",
      "21\n",
      "0\n",
      "1\n",
      "1\n",
      "27\n",
      "76\n",
      "75\n",
      "1\n",
      "75\n",
      "63\n",
      "70\n",
      "76\n",
      "1\n",
      "58\n",
      "70\n",
      "69\n",
      "75\n",
      "73\n",
      "56\n",
      "58\n",
      "75\n",
      "60\n",
      "59\n",
      "1\n",
      "75\n",
      "70\n",
      "1\n",
      "75\n",
      "63\n",
      "64\n",
      "69\n",
      "60\n",
      "1\n",
      "70\n",
      "78\n",
      "69\n",
      "1\n",
      "57\n",
      "73\n",
      "64\n",
      "62\n",
      "63\n",
      "75\n",
      "1\n",
      "60\n",
      "80\n",
      "60\n",
      "74\n",
      "8\n",
      "0\n",
      "1\n",
      "1\n",
      "31\n",
      "60\n",
      "60\n",
      "59\n",
      "5\n",
      "74\n",
      "75\n",
      "1\n",
      "75\n",
      "63\n",
      "80\n",
      "1\n",
      "67\n",
      "64\n",
      "62\n",
      "63\n",
      "75\n",
      "5\n",
      "74\n",
      "1\n",
      "61\n",
      "67\n",
      "56\n",
      "68\n",
      "60\n",
      "1\n",
      "78\n",
      "64\n",
      "75\n",
      "63\n",
      "1\n",
      "74\n",
      "60\n",
      "67\n",
      "61\n",
      "9\n",
      "74\n",
      "76\n",
      "57\n",
      "74\n",
      "75\n",
      "56\n",
      "69\n",
      "75\n",
      "64\n",
      "56\n",
      "67\n",
      "1\n",
      "61\n",
      "76\n",
      "60\n",
      "67\n",
      "8\n",
      "0\n",
      "1\n",
      "1\n",
      "38\n",
      "56\n",
      "66\n",
      "64\n",
      "69\n",
      "62\n",
      "1\n",
      "56\n",
      "1\n",
      "61\n",
      "56\n",
      "68\n",
      "64\n",
      "69\n",
      "60\n",
      "1\n",
      "78\n",
      "63\n",
      "60\n",
      "73\n",
      "60\n",
      "1\n",
      "56\n",
      "57\n",
      "76\n",
      "69\n",
      "59\n",
      "56\n",
      "69\n",
      "58\n",
      "60\n",
      "1\n",
      "67\n",
      "64\n",
      "60\n",
      "74\n",
      "8\n",
      "0\n",
      "1\n",
      "1\n",
      "45\n",
      "63\n",
      "80\n",
      "1\n",
      "74\n",
      "60\n",
      "67\n",
      "61\n",
      "1\n",
      "75\n",
      "63\n",
      "80\n",
      "1\n",
      "61\n",
      "70\n",
      "60\n",
      "8\n",
      "1\n",
      "75\n",
      "70\n",
      "1\n",
      "75\n",
      "63\n",
      "80\n",
      "1\n",
      "74\n",
      "78\n",
      "60\n",
      "60\n",
      "75\n",
      "1\n",
      "74\n",
      "60\n",
      "67\n",
      "61\n",
      "1\n",
      "75\n",
      "70\n",
      "70\n",
      "1\n",
      "58\n",
      "73\n",
      "76\n",
      "60\n",
      "67\n",
      "21\n",
      "0\n",
      "1\n",
      "1\n",
      "45\n",
      "63\n",
      "70\n",
      "76\n",
      "1\n",
      "75\n",
      "63\n",
      "56\n",
      "75\n",
      "1\n",
      "56\n",
      "73\n",
      "75\n",
      "1\n",
      "69\n",
      "70\n",
      "78\n",
      "1\n",
      "75\n",
      "63\n",
      "60\n",
      "1\n",
      "78\n",
      "70\n",
      "73\n",
      "67\n",
      "59\n",
      "5\n",
      "74\n",
      "1\n",
      "61\n",
      "73\n",
      "60\n",
      "74\n",
      "63\n",
      "1\n",
      "70\n",
      "73\n",
      "69\n",
      "56\n",
      "68\n",
      "60\n",
      "69\n",
      "75\n",
      "8\n",
      "0\n",
      "1\n",
      "1\n",
      "26\n",
      "69\n",
      "59\n",
      "1\n",
      "70\n",
      "69\n",
      "67\n",
      "80\n",
      "1\n",
      "63\n",
      "60\n",
      "73\n",
      "56\n",
      "67\n",
      "59\n",
      "1\n",
      "75\n",
      "70\n",
      "1\n",
      "75\n",
      "63\n",
      "60\n",
      "1\n",
      "62\n",
      "56\n",
      "76\n",
      "59\n",
      "80\n",
      "1\n",
      "74\n",
      "71\n",
      "73\n",
      "64\n",
      "69\n",
      "62\n",
      "8\n",
      "0\n",
      "1\n",
      "1\n",
      "48\n",
      "64\n",
      "75\n",
      "63\n",
      "64\n",
      "69\n",
      "1\n",
      "75\n",
      "63\n",
      "64\n",
      "69\n",
      "60\n",
      "1\n",
      "70\n",
      "78\n",
      "69\n",
      "1\n",
      "57\n",
      "76\n"
     ]
    }
   ],
   "source": [
    "for char in char_dataset.take(500):\n",
    "    print(char.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Sequences from the Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = char_dataset.batch(seq_length + 1, drop_remainder=True) \n",
    "# Because of 0 indexing, seq_length + 1\n",
    "# len(text) / seq_length == 45005.03 so dropping that 0.03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our sequences, we will perform the following steps for each one to create our target text sequences:\n",
    "\n",
    "1. Grab the input text sequence\n",
    "2. Assign the target text sequence as the input text sequence shifted by one step forward\n",
    "3. Group them together as a tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_seq_targets(seq):\n",
    "    input_txt = seq[:-1] # Hello my nam\n",
    "    target_txt = seq[1:] # ello my name\n",
    "    return input_txt, target_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sequences.map(create_seq_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Input Sequence and Target Text\n",
    "\n",
    "Target has extra whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0\n",
      "  1  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74\n",
      "  1 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45\n",
      " 63 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74\n",
      " 60  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75\n",
      "  1 56 74  1 75 63 60  1 73 64]\n",
      "\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But as the ri\n",
      "\n",
      "\n",
      "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0  1\n",
      "  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74  1\n",
      " 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45 63\n",
      " 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74 60\n",
      "  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75  1\n",
      " 56 74  1 75 63 60  1 73 64 71]\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But as the rip\n"
     ]
    }
   ],
   "source": [
    "for input_txt, target_txt in  dataset.take(1):\n",
    "    print(input_txt.numpy())\n",
    "    print(''.join(ind_to_char[input_txt.numpy()]))\n",
    "    print('\\n')\n",
    "    print(target_txt.numpy())\n",
    "    # There is an extra whitespace!\n",
    "    print(''.join(ind_to_char[target_txt.numpy()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating training batches\n",
    "\n",
    "Now that we have the actual sequences, we will create the batches, we want to shuffle these sequences into a random order, so the model doesn't overfit to any section of the text, but can instead generate characters given any seed text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size\n",
    "batch_size = 128\n",
    "\n",
    "# Buffer size to shuffle the dataset so it doesn't attempt to shuffle\n",
    "# the entire sequence in memory. Instead, it maintains a buffer in which it shuffles elements\n",
    "buffer_size = 10000\n",
    "\n",
    "dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(128, 130), dtype=tf.int32, name=None), TensorSpec(shape=(128, 130), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the shape of dataset is ( (128,130) , (128,130) ) because it is 128 (batch_size) unique sequences of length 130 characters.\n",
    "\n",
    "There are 2 sets because 1st is input sequence and the other one is target sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " ' ',\n",
       " '!',\n",
       " '\"',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '>',\n",
       " '?',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " '[',\n",
       " ']',\n",
       " '_',\n",
       " '`',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " '|',\n",
       " '}']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because our data is one hot encoded we are going to use sparse_cross_entropy instead of cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function sparse_categorical_crossentropy in module keras.losses:\n",
      "\n",
      "sparse_categorical_crossentropy(y_true, y_pred, from_logits=False, axis=-1, ignore_class=None)\n",
      "    Computes the sparse categorical crossentropy loss.\n",
      "    \n",
      "    Standalone usage:\n",
      "    \n",
      "    >>> y_true = [1, 2]\n",
      "    >>> y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
      "    >>> loss = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred)\n",
      "    >>> assert loss.shape == (2,)\n",
      "    >>> loss.numpy()\n",
      "    array([0.0513, 2.303], dtype=float32)\n",
      "    \n",
      "    >>> y_true = [[[ 0,  2],\n",
      "    ...            [-1, -1]],\n",
      "    ...           [[ 0,  2],\n",
      "    ...            [-1, -1]]]\n",
      "    >>> y_pred = [[[[1.0, 0.0, 0.0], [0.0, 0.0, 1.0]],\n",
      "    ...             [[0.2, 0.5, 0.3], [0.0, 1.0, 0.0]]],\n",
      "    ...           [[[1.0, 0.0, 0.0], [0.0, 0.5, 0.5]],\n",
      "    ...            [[0.2, 0.5, 0.3], [0.0, 1.0, 0.0]]]]\n",
      "    >>> loss = tf.keras.losses.sparse_categorical_crossentropy(\n",
      "    ...   y_true, y_pred, ignore_class=-1)\n",
      "    >>> loss.numpy()\n",
      "    array([[[2.3841855e-07, 2.3841855e-07],\n",
      "            [0.0000000e+00, 0.0000000e+00]],\n",
      "           [[2.3841855e-07, 6.9314730e-01],\n",
      "            [0.0000000e+00, 0.0000000e+00]]], dtype=float32)\n",
      "    \n",
      "    Args:\n",
      "      y_true: Ground truth values.\n",
      "      y_pred: The predicted values.\n",
      "      from_logits: Whether `y_pred` is expected to be a logits tensor. By\n",
      "        default, we assume that `y_pred` encodes a probability distribution.\n",
      "      axis: Defaults to -1. The dimension along which the entropy is\n",
      "        computed.\n",
      "      ignore_class: Optional integer. The ID of a class to be ignored during\n",
      "        loss computation. This is useful, for example, in segmentation\n",
      "        problems featuring a \"void\" class (commonly -1 or 255) in segmentation\n",
      "        maps. By default (`ignore_class=None`), all classes are considered.\n",
      "    \n",
      "    Returns:\n",
      "      Sparse categorical crossentropy loss value.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sparse_categorical_crossentropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sparse_categorical_crossentropy(y_true, y_pred, from_logits=False, axis=-1, ignore_class=None)\n",
    "    Computes the sparse categorical crossentropy loss.\n",
    "\n",
    "**INBUILT FUNCTION**\n",
    "We want logits = True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_cat_loss(y_true, y_pred):\n",
    "    return sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are adding a big single RNN layer instead we can also do many smaller RNN layers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `vocab_size`: Size of the vocabulary (total number of unique words or tokens in the text corpus).\n",
    "- `embed_dim`: Dimensionality of word embeddings (length of the dense vector representation of words)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `rnn_neurons`: The number of neurons or units in the GRU layer. It determines the dimensionality of the GRU's output and internal state.\n",
    "- `return_sequences`: A boolean parameter that specifies whether the GRU layer should return the full sequence of outputs (`True`) or just the last output (`False`) when processing a sequence.\n",
    "- `stateful`: If `True`, the states from the previous batch will be used as the initial states for the current batch.\n",
    "- `recurrent_initializer`: The initialization method for the recurrent weights of the GRU. In this case, 'glorot_uniform' is used, which is a variation of the Xavier/Glorot uniform initializer for the recurrent weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM,Dense,Embedding,Dropout,GRU\n",
    "\n",
    "def create_model(vocab_size, embed_dim, rnn_neurons, batch_size):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Embedding(vocab_size, embed_dim,batch_input_shape=[batch_size, None]))\n",
    "    \n",
    "    # Recurrent_initializer = \"glorot_uniform\" just research, nothing to explain\n",
    "    model.add(GRU(rnn_neurons,return_sequences=True,stateful=True,recurrent_initializer='glorot_uniform'))\n",
    "    \n",
    "    # Final Dense Layer to Predict\n",
    "    model.add(Dense(vocab_size))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss=sparse_cat_loss) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embed_dim = 64\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_neurons = 1026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (128, None, 64)           5376      \n",
      "                                                                 \n",
      " gru (GRU)                   (128, None, 1026)         3361176   \n",
      "                                                                 \n",
      " dense (Dense)               (128, None, 84)           86268     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,452,820\n",
      "Trainable params: 3,452,820\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(\n",
    "    vocab_size=vocab_size,\n",
    "    embed_dim=embed_dim,\n",
    "    rnn_neurons=rnn_neurons,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 130, 84)  <=== (batch_size, sequence_length, vocab_size)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(128, 130, 84), dtype=float32, numpy=\n",
       "array([[[-5.4480555e-04,  5.4546297e-03, -2.4957554e-03, ...,\n",
       "         -1.4721558e-03, -1.0096860e-03, -4.5793606e-03],\n",
       "        [-8.1909867e-04,  7.8510912e-03, -3.4928177e-03, ...,\n",
       "         -2.1210737e-03, -4.0509994e-04, -6.2187877e-03],\n",
       "        [-9.9749118e-04,  8.9958450e-03, -3.9262827e-03, ...,\n",
       "         -2.3590368e-03,  3.3635460e-04, -6.6468641e-03],\n",
       "        ...,\n",
       "        [-9.5425192e-03,  7.5120917e-03,  4.1986881e-03, ...,\n",
       "         -2.4512545e-03, -4.2229393e-03, -2.7720912e-03],\n",
       "        [-1.2513433e-02,  8.6412709e-03,  8.9020270e-04, ...,\n",
       "         -1.8901028e-03,  2.5715036e-03,  7.7130208e-03],\n",
       "        [-1.0650536e-02,  7.1678227e-03, -3.1018071e-03, ...,\n",
       "         -1.0832161e-02, -1.6578261e-03,  6.5392121e-03]],\n",
       "\n",
       "       [[-3.5220666e-03, -4.8247953e-03, -7.5706060e-04, ...,\n",
       "          4.8488360e-03,  5.0071785e-03,  6.5474794e-03],\n",
       "        [ 1.6663829e-03, -6.6346959e-03, -5.1473891e-03, ...,\n",
       "          2.6405463e-04,  3.5925212e-03,  3.3902272e-03],\n",
       "        [ 3.7392473e-03, -3.8259232e-03, -5.7439595e-03, ...,\n",
       "         -3.3942168e-03,  2.8179879e-03,  1.3657287e-03],\n",
       "        ...,\n",
       "        [-4.9909535e-03,  3.0354843e-03, -1.9479881e-04, ...,\n",
       "          6.6155620e-04, -2.5286367e-03, -8.4237661e-05],\n",
       "        [-7.0685241e-03,  4.7535589e-04,  4.7447439e-03, ...,\n",
       "          1.9032857e-03, -3.4531513e-03,  2.1943995e-03],\n",
       "        [-1.0112951e-03,  1.0211276e-03,  5.4304739e-03, ...,\n",
       "          2.5230027e-03, -7.1789268e-03,  5.0556380e-04]],\n",
       "\n",
       "       [[-6.9491826e-03,  4.6878094e-03, -1.1818949e-03, ...,\n",
       "         -4.1102245e-04,  4.1949302e-03,  7.9244263e-03],\n",
       "        [-4.5387605e-03,  6.6645462e-03, -4.3665944e-03, ...,\n",
       "         -1.8888654e-03,  2.3971545e-04, -1.0255151e-03],\n",
       "        [-6.1669806e-03, -2.3684795e-03, -3.1862238e-03, ...,\n",
       "          3.7994729e-03,  5.8111325e-03,  6.3850395e-03],\n",
       "        ...,\n",
       "        [-6.2803645e-03, -1.8553054e-03,  2.0436826e-03, ...,\n",
       "          6.2552034e-03, -7.5309593e-03,  4.2512673e-03],\n",
       "        [-1.6951794e-04, -6.5559270e-03, -5.3877495e-03, ...,\n",
       "          2.0742100e-03, -4.1385428e-03,  1.5916553e-03],\n",
       "        [-6.0128635e-03,  2.2488567e-03, -4.5861164e-03, ...,\n",
       "          3.1264035e-03,  1.0187916e-03,  8.2958192e-03]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-2.3326839e-03,  4.5367149e-03, -3.0540666e-03, ...,\n",
       "          1.1058814e-03, -4.4824881e-03, -2.7844119e-03],\n",
       "        [-4.5072497e-03, -2.9444988e-03, -3.9219689e-03, ...,\n",
       "          5.8620563e-03,  2.8227558e-03,  5.3066406e-03],\n",
       "        [-5.9107132e-03, -2.6110336e-03,  3.1710928e-03, ...,\n",
       "          4.6635298e-03, -7.2270265e-04,  3.8643617e-03],\n",
       "        ...,\n",
       "        [ 1.2621772e-03, -2.8269633e-03, -6.8998449e-03, ...,\n",
       "         -4.4706669e-03, -1.7601673e-03,  2.6197173e-05],\n",
       "        [-4.3454911e-03, -5.3386195e-03, -7.0475563e-03, ...,\n",
       "         -2.9904703e-03, -5.0685643e-03, -1.8080892e-03],\n",
       "        [-2.7365154e-03,  1.8473970e-03, -5.3723902e-03, ...,\n",
       "         -3.1885086e-03, -4.9207592e-03, -5.4892125e-03]],\n",
       "\n",
       "       [[-5.4480555e-04,  5.4546297e-03, -2.4957554e-03, ...,\n",
       "         -1.4721558e-03, -1.0096860e-03, -4.5793606e-03],\n",
       "        [ 1.7850572e-03, -6.6635357e-03, -1.7422140e-03, ...,\n",
       "         -2.1756156e-03,  1.1652384e-03, -1.9734171e-03],\n",
       "        [-4.8546433e-03,  1.1507024e-03,  4.3805093e-03, ...,\n",
       "         -1.3930299e-03, -1.8771936e-03, -3.3165086e-03],\n",
       "        ...,\n",
       "        [ 1.9847036e-03,  2.9581077e-03, -1.0968903e-03, ...,\n",
       "          2.2100601e-03, -7.6100524e-03, -9.2041265e-04],\n",
       "        [-3.8157266e-03, -1.8998852e-03,  4.0051411e-03, ...,\n",
       "          2.3821467e-03, -6.4161019e-03,  2.6522484e-03],\n",
       "        [-9.9278782e-03,  2.9259885e-03, -5.8710831e-04, ...,\n",
       "          9.8815421e-04,  3.3986638e-04,  1.0122802e-02]],\n",
       "\n",
       "       [[-3.5607223e-03,  1.8493372e-03,  2.1822446e-03, ...,\n",
       "          6.2433872e-03, -4.5115300e-03,  2.7113738e-03],\n",
       "        [-8.4206164e-03,  5.0474335e-03, -1.3928243e-03, ...,\n",
       "          2.6870505e-03,  7.2261062e-04,  8.7314844e-03],\n",
       "        [-9.2032803e-03, -1.0469722e-03, -6.8899798e-03, ...,\n",
       "          7.0436415e-04, -4.3290253e-03,  1.0388806e-03],\n",
       "        ...,\n",
       "        [ 5.9128134e-04, -5.2517967e-04, -6.2036621e-03, ...,\n",
       "         -5.3889975e-03,  8.4669766e-04,  4.4907518e-03],\n",
       "        [-1.4789053e-05,  4.7327308e-03, -4.7543868e-03, ...,\n",
       "         -5.2744430e-03, -9.9025981e-04, -1.6576194e-03],\n",
       "        [ 2.8892898e-03, -2.5473735e-03, -6.9177160e-03, ...,\n",
       "         -5.4640290e-03,  1.7177491e-03,  4.2086036e-04]]], dtype=float32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "\n",
    "    # Predict off some random batch\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "\n",
    "    # Display the dimensions of the predictions\n",
    "    print(example_batch_predictions.shape,\n",
    "        \" <=== (batch_size, sequence_length, vocab_size)\")\n",
    "\n",
    "example_batch_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(130, 1), dtype=int64, numpy=\n",
       "array([[36],\n",
       "       [64],\n",
       "       [30],\n",
       "       [31],\n",
       "       [65],\n",
       "       [12],\n",
       "       [62],\n",
       "       [74],\n",
       "       [81],\n",
       "       [15],\n",
       "       [50],\n",
       "       [21],\n",
       "       [35],\n",
       "       [44],\n",
       "       [57],\n",
       "       [58],\n",
       "       [ 5],\n",
       "       [ 9],\n",
       "       [ 6],\n",
       "       [63],\n",
       "       [ 7],\n",
       "       [72],\n",
       "       [83],\n",
       "       [46],\n",
       "       [71],\n",
       "       [13],\n",
       "       [42],\n",
       "       [ 7],\n",
       "       [ 7],\n",
       "       [81],\n",
       "       [16],\n",
       "       [60],\n",
       "       [30],\n",
       "       [78],\n",
       "       [61],\n",
       "       [79],\n",
       "       [ 1],\n",
       "       [82],\n",
       "       [ 4],\n",
       "       [56],\n",
       "       [37],\n",
       "       [12],\n",
       "       [51],\n",
       "       [73],\n",
       "       [38],\n",
       "       [42],\n",
       "       [19],\n",
       "       [ 8],\n",
       "       [ 3],\n",
       "       [10],\n",
       "       [78],\n",
       "       [ 9],\n",
       "       [26],\n",
       "       [45],\n",
       "       [73],\n",
       "       [12],\n",
       "       [19],\n",
       "       [44],\n",
       "       [18],\n",
       "       [44],\n",
       "       [39],\n",
       "       [ 4],\n",
       "       [50],\n",
       "       [62],\n",
       "       [25],\n",
       "       [61],\n",
       "       [30],\n",
       "       [56],\n",
       "       [41],\n",
       "       [21],\n",
       "       [21],\n",
       "       [64],\n",
       "       [62],\n",
       "       [48],\n",
       "       [ 7],\n",
       "       [43],\n",
       "       [56],\n",
       "       [44],\n",
       "       [61],\n",
       "       [30],\n",
       "       [ 2],\n",
       "       [32],\n",
       "       [82],\n",
       "       [30],\n",
       "       [42],\n",
       "       [ 2],\n",
       "       [16],\n",
       "       [34],\n",
       "       [30],\n",
       "       [50],\n",
       "       [24],\n",
       "       [45],\n",
       "       [26],\n",
       "       [15],\n",
       "       [23],\n",
       "       [13],\n",
       "       [82],\n",
       "       [15],\n",
       "       [11],\n",
       "       [21],\n",
       "       [42],\n",
       "       [74],\n",
       "       [51],\n",
       "       [20],\n",
       "       [52],\n",
       "       [36],\n",
       "       [65],\n",
       "       [40],\n",
       "       [60],\n",
       "       [ 4],\n",
       "       [ 9],\n",
       "       [16],\n",
       "       [54],\n",
       "       [55],\n",
       "       [21],\n",
       "       [24],\n",
       "       [81],\n",
       "       [50],\n",
       "       [10],\n",
       "       [ 6],\n",
       "       [ 8],\n",
       "       [64],\n",
       "       [78],\n",
       "       [46],\n",
       "       [77],\n",
       "       [75],\n",
       "       [71],\n",
       "       [ 1],\n",
       "       [74],\n",
       "       [65]], dtype=int64)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([36, 64, 30, 31, 65, 12, 62, 74, 81, 15, 50, 21, 35, 44, 57, 58,  5,\n",
       "        9,  6, 63,  7, 72, 83, 46, 71, 13, 42,  7,  7, 81, 16, 60, 30, 78,\n",
       "       61, 79,  1, 82,  4, 56, 37, 12, 51, 73, 38, 42, 19,  8,  3, 10, 78,\n",
       "        9, 26, 45, 73, 12, 19, 44, 18, 44, 39,  4, 50, 62, 25, 61, 30, 56,\n",
       "       41, 21, 21, 64, 62, 48,  7, 43, 56, 44, 61, 30,  2, 32, 82, 30, 42,\n",
       "        2, 16, 34, 30, 50, 24, 45, 26, 15, 23, 13, 82, 15, 11, 21, 42, 74,\n",
       "       51, 20, 52, 36, 65, 40, 60,  4,  9, 16, 54, 55, 21, 24, 81, 50, 10,\n",
       "        6,  8, 64, 78, 46, 77, 75, 71,  1, 74, 65], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reformat to not be a lists of lists\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the input seq: \n",
      "\n",
      "    The faults of fools but folly.\n",
      "  COMINIUS. Ever right.\n",
      "  CORIOLANUS. Menenius ever, ever.\n",
      "  HERALD. Give way there, and go on.\n",
      "\n",
      "\n",
      "Next Char Predictions: \n",
      "\n",
      "KiEFj1gsz4Y:JSbc'-(h)q}Up2Q))z5eEwfx |&aL1ZrMQ8,\".w-ATr18S7SN&Yg?fEaP::igW)RaSfE!G|EQ!5IEY>TA4<2|40:QsZ9[KjOe&-5_`:>zY.(,iwUvtp sj\n"
     ]
    }
   ],
   "source": [
    "print(\"Given the input seq: \\n\")\n",
    "print(\"\".join(ind_to_char[input_example_batch[0]]))\n",
    "print('\\n')\n",
    "print(\"Next Char Predictions: \\n\")\n",
    "print(\"\".join(ind_to_char[sampled_indices ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After confirming the dimensions are working, let's train our network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324/324 [==============================] - 79s 231ms/step - loss: 2.5714\n",
      "Epoch 2/30\n",
      "324/324 [==============================] - 80s 243ms/step - loss: 1.7418\n",
      "Epoch 3/30\n",
      "324/324 [==============================] - 81s 246ms/step - loss: 1.4656\n",
      "Epoch 4/30\n",
      "324/324 [==============================] - 81s 246ms/step - loss: 1.3441\n",
      "Epoch 5/30\n",
      "324/324 [==============================] - 83s 250ms/step - loss: 1.2789\n",
      "Epoch 6/30\n",
      "324/324 [==============================] - 81s 245ms/step - loss: 1.2377\n",
      "Epoch 7/30\n",
      "324/324 [==============================] - 82s 247ms/step - loss: 1.2067\n",
      "Epoch 8/30\n",
      "324/324 [==============================] - 82s 247ms/step - loss: 1.1832\n",
      "Epoch 9/30\n",
      "324/324 [==============================] - 81s 246ms/step - loss: 1.1626\n",
      "Epoch 10/30\n",
      "324/324 [==============================] - 81s 245ms/step - loss: 1.1450\n",
      "Epoch 11/30\n",
      "324/324 [==============================] - 82s 247ms/step - loss: 1.1292\n",
      "Epoch 12/30\n",
      "324/324 [==============================] - 82s 247ms/step - loss: 1.1147\n",
      "Epoch 13/30\n",
      "324/324 [==============================] - 81s 246ms/step - loss: 1.1021\n",
      "Epoch 14/30\n",
      "324/324 [==============================] - 81s 246ms/step - loss: 1.0887\n",
      "Epoch 15/30\n",
      "324/324 [==============================] - 81s 246ms/step - loss: 1.0771\n",
      "Epoch 16/30\n",
      "324/324 [==============================] - 81s 246ms/step - loss: 1.0653\n",
      "Epoch 17/30\n",
      "324/324 [==============================] - 81s 245ms/step - loss: 1.0549\n",
      "Epoch 18/30\n",
      "324/324 [==============================] - 81s 246ms/step - loss: 1.0437\n",
      "Epoch 19/30\n",
      "324/324 [==============================] - 79s 240ms/step - loss: 1.0343\n",
      "Epoch 20/30\n",
      "324/324 [==============================] - 79s 240ms/step - loss: 1.0249\n",
      "Epoch 21/30\n",
      "324/324 [==============================] - 79s 240ms/step - loss: 1.0160\n",
      "Epoch 22/30\n",
      "324/324 [==============================] - 80s 241ms/step - loss: 1.0078\n",
      "Epoch 23/30\n",
      "324/324 [==============================] - 80s 241ms/step - loss: 1.0003\n",
      "Epoch 24/30\n",
      "324/324 [==============================] - 79s 241ms/step - loss: 0.9935\n",
      "Epoch 25/30\n",
      "324/324 [==============================] - 79s 241ms/step - loss: 0.9870\n",
      "Epoch 26/30\n",
      "324/324 [==============================] - 79s 241ms/step - loss: 0.9814\n",
      "Epoch 27/30\n",
      "324/324 [==============================] - 80s 241ms/step - loss: 0.9760\n",
      "Epoch 28/30\n",
      "324/324 [==============================] - 79s 241ms/step - loss: 0.9714\n",
      "Epoch 29/30\n",
      "324/324 [==============================] - 79s 241ms/step - loss: 0.9676\n",
      "Epoch 30/30\n",
      "324/324 [==============================] - 79s 241ms/step - loss: 0.9639\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1eafcf77e20>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# epochs = 30\n",
    "# model.fit(dataset,epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model:\n",
    "# model.save('./model/text_generation.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the model:\n",
    "model = create_model(vocab_size, embed_dim, rnn_neurons, batch_size=1)\n",
    "\n",
    "model.load_weights('./model/text_generation.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Text:\n",
    "Currently our model only expects 128 sequences at a time. We can create a new model that only expects a `batch_size=1`. We can create a new model with this batch size, then load our saved models weights. Then call .build() on the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (1, None, 64)             5376      \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (1, None, 1026)           3361176   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (1, None, 84)             86268     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,452,820\n",
      "Trainable params: 3,452,820\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_seed, gen_size=100, temp=1.0):\n",
    "    '''\n",
    "    model: Trained Model to Generate Text\n",
    "    start_seed: Intial Seed text in string form\n",
    "    gen_size: Number of characters to generate\n",
    "\n",
    "    Basic idea behind this function is to take in some seed text, format it so\n",
    "    that it is in the correct shape for our network, then loop the sequence as\n",
    "    we keep adding our own predicted characters. Similar to our work in the RNN\n",
    "    time series problems.\n",
    "    '''\n",
    "\n",
    "    # Number of characters to generate\n",
    "    num_generate = gen_size\n",
    "\n",
    "    # Vecotrizing starting seed text\n",
    "    input_eval = [char_to_ind[s] for s in start_seed]\n",
    "\n",
    "    # Expand to match batch format shape\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    # Empty list to hold resulting generated text\n",
    "    text_generated = []\n",
    "\n",
    "    # Temperature effects randomness in our resulting text\n",
    "    # The term is derived from entropy/thermodynamics.\n",
    "    # The temperature is used to effect probability of next characters.\n",
    "    # Higher probability == lesss surprising/ more expected\n",
    "    # Lower temperature == more surprising / less expected\n",
    "\n",
    "    temperature = temp\n",
    "\n",
    "    # Here batch size == 1\n",
    "    model.reset_states()\n",
    "\n",
    "    for i in range(num_generate):\n",
    "\n",
    "        # Generate Predictions\n",
    "        predictions = model(input_eval)\n",
    "\n",
    "        # Remove the batch shape dimension\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "        # Use a cateogircal disitribution to select the next character\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(\n",
    "            predictions, num_samples=1)[-1, 0].numpy()\n",
    "\n",
    "        # Pass the predicted charracter for the next input\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        # Transform back to character letter\n",
    "        text_generated.append(ind_to_char[predicted_id])\n",
    "\n",
    "    return (start_seed + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flowers,\n",
      "    As perfect is upon him.\n",
      "  Corn. What amaze her silver, till the livele court herself wills make enough\n",
      "    on thee.\n",
      "  TROILUS. Weds, sick finds of love.\n",
      "  FRANCISCE. Why, what a man is this?\n",
      "  PROAPETRSSANIO. Well, believe the heaven speaks so;\n",
      "    And so have I\n",
      "    And my poor corse, and not by vow in wars,\n",
      "    So your ostentation, supple your act,\n",
      "    Made good her worthiness, better brief with your age.\n",
      "  ARCHBISHOP. Seven gentlemen; this shapes creat the at,\n",
      "               In thy shame is laid upon his forward.  \n",
      "\n",
      "                    Enter CURTH\n",
      "\n",
      " CAMPEIU.\n",
      "                The Goths have no advantage on yond title rectify\n",
      "    To commend his likely. Thy looks lieatch be otherwise.-\n",
      "  It seems you like a bird, whose horror help as he were,\n",
      "    Is't to redeem or fault?\n",
      "  FIRST SERVANT. Ay, but not die. Your honours is a goodly birds to fight\n",
      "    Left is but his own burial. O my brother Troyan?\n",
      "  MIRANDA. Yes; ere I could work in: and, indeed,  \n",
      "    As your gold-much gainst with \n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model,\"flower\",gen_size=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
